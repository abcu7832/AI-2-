# 250704 í”„ë¡œì íŠ¸ ì§„í–‰ìƒí™©
* ê°ì ê°œë°œí•œ ê¸°ìˆ  merge
```python
# AI ì‹œí—˜ ê°ë…ê´€
import cv2
import mediapipe as mp
import numpy as np
import time
from datetime import datetime
import json
import sys
import os
import face_recognition
import threading
import argparse
from pathlib import Path

class AIExamSupervisorIntegrated:
    def __init__(self, config_path="config.json"):
        """í†µí•© AI ì‹œí—˜ ê°ë…ê´€ ì´ˆê¸°í™”"""
        
        # ì„¤ì • ë¡œë“œ
        self.load_config(config_path)
        
        # MediaPipe ì´ˆê¸°í™” (ë¼ì¦ˆë² ë¦¬íŒŒì´ ìµœì í™”)
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            refine_landmarks=False,  # ë¼ì¦ˆë² ë¦¬íŒŒì´ ìµœì í™”
            static_image_mode=False, 
            max_num_faces=2,  # ë©”ëª¨ë¦¬ ì ˆì•½
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        self.mp_drawing = mp.solutions.drawing_utils
        
        # ì–¼êµ´ ëœë“œë§ˆí¬ í¬ì¸íŠ¸ ì •ì˜
        self.NOSE_TIP = 1
        self.LEFT_EYE_LEFT = 33
        self.RIGHT_EYE_RIGHT = 263
        self.LEFT_MOUTH = 61
        self.RIGHT_MOUTH = 291
        self.CHIN = 18
        
        # ëˆˆ ì˜ì—­ í¬ì¸íŠ¸ (ì•„ì´íŠ¸ë˜í‚¹ìš©)
        self.LEFT_EYE = [33, 160, 158, 133, 153, 144]
        self.RIGHT_EYE = [362, 387, 385, 263, 373, 380]
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        self.system_phase = "IDENTITY_CHECK"  # IDENTITY_CHECK -> EXAM_MONITORING
        self.authenticated_user = None
        self.exam_start_time = None
        
        # ìœ„ë°˜ ìƒíƒœ ì´ˆê¸°í™”
        self.reset_violation_states()
        
        # ì–¼êµ´ ì¶”ì  ë³€ìˆ˜ë“¤
        self.last_face_landmarks = None
        self.face_lost_time = 0
        
        # ì•„ì´íŠ¸ë˜í‚¹ ë³€ìˆ˜ë“¤
        self.gaze_baseline = None
        self.frame_count = 0
        self.baseline_sum = 0
        self.last_gaze_violation_time = 0
        
        # ë¡œê¹… ì‹œìŠ¤í…œ
        self.violation_log = []
        self.total_violations = 0
        self.identity_attempts = 0
        
        # í„°ë¯¸ë„ ì¶œë ¥ ì„¤ì •
        self.last_status_print = 0
        
        # ANSI ìƒ‰ìƒ ì½”ë“œ
        self.setup_colors()
        
        # ë°ì´í„°ì…‹ ê²½ë¡œ í™•ì¸
        self.ensure_dataset_exists()
        
        print(f"{self.BOLD}{self.CYAN}ğŸ”’ AI ì‹œí—˜ ê°ë…ê´€ ì‹œìŠ¤í…œ v2.0 (ë¼ì¦ˆë² ë¦¬íŒŒì´5 ìµœì í™”){self.END}")
        print(f"{self.GREEN}âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ{self.END}")
        print("=" * 70)
    
    def load_config(self, config_path):
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        default_config = {
            "camera": {
                "index": 0,
                "width": 640,
                "height": 480,
                "fps": 20,
                "mirror": True
            },
            "detection": {
                "x_threshold": 0.15,
                "y_threshold": 0.5,
                "sustained_time": 2.0,
                "gaze_margin": 0.5,
                "face_lost_threshold": 1.0
            },
            "identity": {
                "dataset_path": "./dataset",
                "tolerance": 0.5,
                "max_attempts": 5
            },
            "system": {
                "print_interval": 1.0,
                "baseline_frames": 30,
                "gaze_debug_mode": False,
                "save_video": True,
                "log_path": "./logs"
            }
        }
        
        if os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                # ê¸°ë³¸ê°’ê³¼ ë³‘í•©
                for key in default_config:
                    if key not in config:
                        config[key] = default_config[key]
                    else:
                        for subkey in default_config[key]:
                            if subkey not in config[key]:
                                config[key][subkey] = default_config[key][subkey]
            except Exception as e:
                print(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
                config = default_config
        else:
            config = default_config
            # ê¸°ë³¸ ì„¤ì • íŒŒì¼ ìƒì„±
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False)
        
        # ì„¤ì •ê°’ ì ìš©
        self.config = config
        self.CAMERA_INDEX = config["camera"]["index"]
        self.CAMERA_WIDTH = config["camera"]["width"]
        self.CAMERA_HEIGHT = config["camera"]["height"]
        self.CAMERA_FPS = config["camera"]["fps"]
        self.MIRROR_CAMERA = config["camera"]["mirror"]
        
        self.X_THRESHOLD = config["detection"]["x_threshold"]
        self.Y_THRESHOLD = config["detection"]["y_threshold"]
        self.SUSTAINED_TIME = config["detection"]["sustained_time"]
        self.GAZE_MARGIN = config["detection"]["gaze_margin"]
        self.FACE_LOST_THRESHOLD = config["detection"]["face_lost_threshold"]
        
        self.DATASET_PATH = config["identity"]["dataset_path"]
        self.FACE_TOLERANCE = config["identity"]["tolerance"]
        self.MAX_IDENTITY_ATTEMPTS = config["identity"]["max_attempts"]
        
        self.PRINT_INTERVAL = config["system"]["print_interval"]
        self.BASELINE_FRAMES = config["system"]["baseline_frames"]
        self.GAZE_DEBUG_MODE = config["system"]["gaze_debug_mode"]
        self.SAVE_VIDEO = config["system"]["save_video"]
        self.LOG_PATH = config["system"]["log_path"]
    
    def setup_colors(self):
        """ANSI ìƒ‰ìƒ ì½”ë“œ ì„¤ì •"""
        self.RED = '\033[91m'
        self.GREEN = '\033[92m'
        self.YELLOW = '\033[93m'
        self.BLUE = '\033[94m'
        self.MAGENTA = '\033[95m'
        self.CYAN = '\033[96m'
        self.WHITE = '\033[97m'
        self.BOLD = '\033[1m'
        self.UNDERLINE = '\033[4m'
        self.END = '\033[0m'
    
    def ensure_dataset_exists(self):
        """ë°ì´í„°ì…‹ í´ë” ì¡´ì¬ í™•ì¸ ë° ìƒì„±"""
        Path(self.DATASET_PATH).mkdir(exist_ok=True)
        Path(self.LOG_PATH).mkdir(exist_ok=True)
        
        # ë°ì´í„°ì…‹ íŒŒì¼ í™•ì¸
        dataset_files = list(Path(self.DATASET_PATH).glob("*.jpg")) + \
                       list(Path(self.DATASET_PATH).glob("*.jpeg")) + \
                       list(Path(self.DATASET_PATH).glob("*.png"))
        
        if not dataset_files:
            print(f"{self.YELLOW}âš ï¸  ë°ì´í„°ì…‹ í´ë”ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {self.DATASET_PATH}{self.END}")
            print(f"{self.YELLOW}   ì¸ì¦ìš© ì–¼êµ´ ì´ë¯¸ì§€ë¥¼ '{self.DATASET_PATH}' í´ë”ì— ì¶”ê°€í•˜ì„¸ìš”{self.END}")
    
    def reset_violation_states(self):
        """ìœ„ë°˜ ìƒíƒœ ì´ˆê¸°í™”"""
        self.is_head_abnormal = False
        self.head_abnormal_start_time = time.time()
        self.is_head_violation = False
        
        self.is_multiple_faces = False
        self.multiple_faces_start_time = time.time()
        self.is_multiple_faces_violation = False
        
        self.is_no_face = False
        self.no_face_start_time = time.time()
        self.is_no_face_violation = False
        
        self.is_gaze_abnormal = False
        self.gaze_abnormal_start_time = time.time()
        self.is_gaze_violation = False
    
    def find_camera(self):
        """ì¹´ë©”ë¼ ì°¾ê¸° (ë¼ì¦ˆë² ë¦¬íŒŒì´ ìµœì í™”)"""
        # ì„¤ì •ëœ ì¹´ë©”ë¼ ì¸ë±ìŠ¤ë¶€í„° ì‹œë„
        camera_indices = [self.CAMERA_INDEX] + [i for i in range(5) if i != self.CAMERA_INDEX]
        
        for camera_idx in camera_indices:
            try:
                cap = cv2.VideoCapture(camera_idx)
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.CAMERA_WIDTH)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.CAMERA_HEIGHT)
                cap.set(cv2.CAP_PROP_FPS, self.CAMERA_FPS)
                cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # ë²„í¼ í¬ê¸° ìµœì†Œí™”
                
                if cap.isOpened():
                    ret, frame = cap.read()
                    if ret:
                        print(f"{self.GREEN}âœ… ì¹´ë©”ë¼ {camera_idx}ë²ˆ ì—°ê²° ì„±ê³µ ({self.CAMERA_WIDTH}x{self.CAMERA_HEIGHT}@{self.CAMERA_FPS}fps){self.END}")
                        return cap
                    cap.release()
            except Exception as e:
                continue
        return None
    
    def compare_with_dataset(self, captured_image_path):
        """ë°ì´í„°ì…‹ê³¼ ì–¼êµ´ ë¹„êµ"""
        try:
            # ìº¡ì²˜ ì´ë¯¸ì§€ ë¡œë“œ ë° ì–¼êµ´ ì¸ì½”ë”©
            unknown_image = face_recognition.load_image_file(captured_image_path)
            face_locations = face_recognition.face_locations(unknown_image, model="hog")  # ë¼ì¦ˆë² ë¦¬íŒŒì´ ìµœì í™”
            unknown_encodings = face_recognition.face_encodings(unknown_image, face_locations)

            if len(unknown_encodings) == 0:
                print(f"{self.RED}â— ìº¡ì²˜ëœ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.{self.END}")
                return None

            unknown_encoding = unknown_encodings[0]

            # ë°ì´í„°ì…‹ í´ë” ë‚´ ì´ë¯¸ì§€ì™€ ë¹„êµ
            dataset_files = []
            for ext in ["*.jpg", "*.jpeg", "*.png"]:
                dataset_files.extend(Path(self.DATASET_PATH).glob(ext))
            
            if not dataset_files:
                print(f"{self.RED}âŒ ë°ì´í„°ì…‹ì— ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.{self.END}")
                return None

            best_match = None
            best_distance = float('inf')
            
            for file_path in dataset_files:
                try:
                    known_image = face_recognition.load_image_file(str(file_path))
                    known_encodings = face_recognition.face_encodings(known_image)

                    if not known_encodings:
                        print(f"â— ì–¼êµ´ ì¸ì‹ ì‹¤íŒ¨: {file_path.name}")
                        continue

                    known_encoding = known_encodings[0]
                    distance = face_recognition.face_distance([known_encoding], unknown_encoding)[0]
                    
                    print(f"   ğŸ“Š {file_path.name}: ê±°ë¦¬ {distance:.4f}")
                    
                    if distance < best_distance:
                        best_distance = distance
                        best_match = file_path.stem  # í™•ì¥ì ì œì™¸í•œ íŒŒì¼ëª…
                        
                except Exception as e:
                    print(f"â— íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ {file_path.name}: {e}")
                    continue

            # ë§¤ì¹­ ê²°ê³¼ íŒë‹¨
            if best_match and best_distance <= self.FACE_TOLERANCE:
                print(f"{self.GREEN}âœ… [ë§¤ì¹­ ì„±ê³µ] {best_match} (ê±°ë¦¬: {best_distance:.4f}){self.END}")
                return best_match
            else:
                print(f"{self.RED}âŒ [ë§¤ì¹­ ì‹¤íŒ¨] ìµœì†Œ ê±°ë¦¬: {best_distance:.4f} (ì„ê³„ê°’: {self.FACE_TOLERANCE}){self.END}")
                return None
                
        except Exception as e:
            print(f"{self.RED}âŒ ì–¼êµ´ ì¸ì‹ ì²˜ë¦¬ ì˜¤ë¥˜: {e}{self.END}")
            return None
    
    def identity_verification_phase(self, cap):
        """ì‹ ì› í™•ì¸ ë‹¨ê³„"""
        print(f"\n{self.BOLD}{self.BLUE}ğŸ” 1ë‹¨ê³„: ì‹ ì› í™•ì¸{self.END}")
        print(f"{self.CYAN}ì¹´ë©”ë¼ í™”ë©´ì—ì„œ 'c' í‚¤ë¥¼ ëˆŒëŸ¬ ì–¼êµ´ì„ ìº¡ì²˜í•˜ì„¸ìš”{self.END}")
        print(f"{self.CYAN}ìµœëŒ€ {self.MAX_IDENTITY_ATTEMPTS}íšŒ ì‹œë„ ê°€ëŠ¥, 'q' í‚¤ë¡œ ì¢…ë£Œ{self.END}")
        print("-" * 70)
        
        while self.identity_attempts < self.MAX_IDENTITY_ATTEMPTS:
            ret, frame = cap.read()
            if not ret:
                print(f"{self.RED}âŒ í”„ë ˆì„ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.{self.END}")
                return False
            
            if self.MIRROR_CAMERA:
                frame = cv2.flip(frame, 1)
            
            # ìƒíƒœ ì •ë³´ í‘œì‹œ
            cv2.putText(frame, f"Identity Verification ({self.identity_attempts + 1}/{self.MAX_IDENTITY_ATTEMPTS})", 
                       (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            cv2.putText(frame, "Press 'c' to capture, 'q' to quit", 
                       (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            
            # ì–¼êµ´ ê°ì§€ í‘œì‹œ
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            face_locations = face_recognition.face_locations(frame_rgb, model="hog")
            
            for (top, right, bottom, left) in face_locations:
                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)
                cv2.putText(frame, "Face Detected", (left, top - 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
            
            cv2.imshow("AI Exam Supervisor - Identity Check", frame)
            
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                print(f"{self.YELLOW}ì‹ ì› í™•ì¸ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.{self.END}")
                return False
            elif key == ord('c'):
                self.identity_attempts += 1
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"identity_check_{timestamp}_{self.identity_attempts}.png"
                cv2.imwrite(filename, frame)
                
                print(f"\nğŸ“¸ {self.identity_attempts}ë²ˆì§¸ ì‹œë„: {filename} ì €ì¥ ì™„ë£Œ")
                print("ğŸ” ì–¼êµ´ ì¸ì‹ ì²˜ë¦¬ ì¤‘...")
                
                # ì–¼êµ´ ë¹„êµ ìˆ˜í–‰
                matched_name = self.compare_with_dataset(filename)
                
                if matched_name:
                    self.authenticated_user = matched_name
                    print(f"{self.BOLD}{self.GREEN}ğŸ‰ ì¸ì¦ ì„±ê³µ! {matched_name}ë‹˜, í™˜ì˜í•©ë‹ˆë‹¤.{self.END}")
                    
                    # ìº¡ì²˜ íŒŒì¼ ì •ë¦¬
                    try:
                        os.remove(filename)
                    except:
                        pass
                    
                    return True
                else:
                    print(f"{self.RED}âŒ ì¸ì¦ ì‹¤íŒ¨ ({self.identity_attempts}/{self.MAX_IDENTITY_ATTEMPTS}){self.END}")
                    if self.identity_attempts < self.MAX_IDENTITY_ATTEMPTS:
                        print(f"{self.YELLOW}ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”. ë‚¨ì€ íšŸìˆ˜: {self.MAX_IDENTITY_ATTEMPTS - self.identity_attempts}íšŒ{self.END}")
                    
                    # ì‹¤íŒ¨í•œ ìº¡ì²˜ íŒŒì¼ ì •ë¦¬
                    try:
                        os.remove(filename)
                    except:
                        pass
                
                print("-" * 70)
        
        print(f"{self.RED}âŒ ì‹ ì› í™•ì¸ ì‹¤íŒ¨: ìµœëŒ€ ì‹œë„ íšŸìˆ˜ ì´ˆê³¼{self.END}")
        return False
    
    def get_landmarks_coords(self, face_landmarks, image_w, image_h):
        """MediaPipe ëœë“œë§ˆí¬ë¥¼ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜"""
        coords = []
        for landmark in face_landmarks.landmark:
            x = int(landmark.x * image_w)
            y = int(landmark.y * image_h)
            coords.append([x, y])
        return np.array(coords)
    
    def get_head_direction(self, landmarks, image_w, image_h):
        """ë¨¸ë¦¬ ë°©í–¥ íŒë‹¨"""
        nose_tip = landmarks[self.NOSE_TIP]
        left_eye_left = landmarks[self.LEFT_EYE_LEFT]
        right_eye_right = landmarks[self.RIGHT_EYE_RIGHT]
        
        # ì–¼êµ´ ì¤‘ì‹¬ì„  ê³„ì‚°
        face_width = abs(right_eye_right[0] - left_eye_left[0])
        face_center_x = (left_eye_left[0] + right_eye_right[0]) / 2
        
        # ì¢Œìš° ë°©í–¥ íŒë‹¨
        offset_x = nose_tip[0] - face_center_x
        
        # ìƒí•˜ ë°©í–¥ íŒë‹¨
        eye_center_y = (left_eye_left[1] + right_eye_right[1]) / 2
        offset_y = nose_tip[1] - eye_center_y
        
        if face_width == 0:
            return "Forward", 0, 0
        
        # ì •ê·œí™”
        x_ratio = offset_x / face_width
        y_ratio = offset_y / face_width
        
        # ë°©í–¥ íŒë‹¨
        if y_ratio > self.Y_THRESHOLD:
            return "Down", x_ratio, y_ratio
        elif x_ratio > self.X_THRESHOLD:
            return "Left", x_ratio, y_ratio
        elif x_ratio < -self.X_THRESHOLD:
            return "Right", x_ratio, y_ratio
        else:
            return "Forward", x_ratio, y_ratio
    
    def get_gaze_ratio(self, eye_indices, landmarks, frame, gray):
        """ì‹œì„  ë°©í–¥ ê³„ì‚°"""
        h, w = frame.shape[:2]
        
        try:
            # ëˆˆ ì˜ì—­ ì¢Œí‘œ ê³„ì‚°
            eye_region = np.array([(int(landmarks[i][0] * w), int(landmarks[i][1] * h)) 
                                  for i in eye_indices], np.int32)
            
            # ë§ˆìŠ¤í¬ ìƒì„±
            mask = np.zeros((h, w), dtype=np.uint8)
            cv2.fillPoly(mask, [eye_region], 255)
            
            # ëˆˆ ì˜ì—­ ì¶”ì¶œ
            eye = cv2.bitwise_and(gray, gray, mask=mask)
            
            # ê²½ê³„ ì¢Œí‘œ ê³„ì‚°
            min_x = np.min(eye_region[:, 0])
            max_x = np.max(eye_region[:, 0])
            min_y = np.min(eye_region[:, 1])
            max_y = np.max(eye_region[:, 1])
            
            # ê²½ê³„ ê²€ì‚¬
            if min_x >= max_x or min_y >= max_y or min_x < 0 or min_y < 0 or max_x >= w or max_y >= h:
                return 1.0
            
            # ëˆˆ ì˜ì—­ í¬ë¡­
            gray_eye = eye[min_y:max_y, min_x:max_x]
            
            if gray_eye.size == 0:
                return 1.0
            
            # ì„ê³„ê°’ ì ìš©
            _, threshold_eye = cv2.threshold(gray_eye, 70, 255, cv2.THRESH_BINARY)
            
            th_h, th_w = threshold_eye.shape
            
            if th_w < 2:
                return 1.0
            
            # ì¢Œìš° ì˜ì—­ì˜ í°ìƒ‰ í”½ì…€ ìˆ˜ ê³„ì‚°
            left_white = cv2.countNonZero(threshold_eye[:, 0:int(th_w / 2)])
            right_white = cv2.countNonZero(threshold_eye[:, int(th_w / 2):])
            
            if left_white == 0 or right_white == 0:
                return 1.0
            else:
                return left_white / right_white
                
        except Exception as e:
            return 1.0
    
    def update_violation_states(self, face_count, head_direction, gaze_ratio):
        """ìœ„ë°˜ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        current_time = time.time()
        
        # 1. ë‹¤ì¤‘ ì¸ë¬¼ ê°ì§€
        current_multiple_faces = face_count > 1
        if current_multiple_faces != self.is_multiple_faces:
            if not current_multiple_faces and self.is_multiple_faces_violation:
                total_duration = current_time - self.multiple_faces_start_time
                self.print_violation_alert("ë‹¤ì¤‘ ì¸ë¬¼", f"ê°ì§€ëœ ì–¼êµ´ ìˆ˜: {face_count}", 
                                         is_start=False, duration=total_duration)
            
            self.is_multiple_faces = current_multiple_faces
            self.multiple_faces_start_time = current_time
            self.is_multiple_faces_violation = False
        
        if self.is_multiple_faces:
            duration = current_time - self.multiple_faces_start_time
            if duration >= self.SUSTAINED_TIME and not self.is_multiple_faces_violation:
                self.is_multiple_faces_violation = True
                self.print_violation_alert("ë‹¤ì¤‘ ì¸ë¬¼", f"ê°ì§€ëœ ì–¼êµ´ ìˆ˜: {face_count}", 
                                         is_start=True, duration=duration)
            elif duration < self.SUSTAINED_TIME and duration > 0.5:
                self.print_warning("ë‹¤ì¤‘ ì¸ë¬¼ ê°ì§€", f"{face_count}ëª… ê°ì§€ë¨", duration)
        
        # 2. í™”ë©´ ì´íƒˆ ê°ì§€
        current_no_face = face_count == 0
        if current_no_face != self.is_no_face:
            if not current_no_face and self.is_no_face_violation:
                total_duration = current_time - self.no_face_start_time
                self.print_violation_alert("í™”ë©´ ì´íƒˆ", "í™”ë©´ì—ì„œ ì™„ì „íˆ ì´íƒˆ", 
                                         is_start=False, duration=total_duration)
            
            self.is_no_face = current_no_face
            self.no_face_start_time = current_time
            self.is_no_face_violation = False
        
        if self.is_no_face:
            duration = current_time - self.no_face_start_time
            if duration >= self.SUSTAINED_TIME and not self.is_no_face_violation:
                self.is_no_face_violation = True
                self.print_violation_alert("í™”ë©´ ì´íƒˆ", "í™”ë©´ì—ì„œ ì™„ì „íˆ ì´íƒˆ", 
                                         is_start=True, duration=duration)
            elif duration < self.SUSTAINED_TIME and duration > 0.5:
                self.print_warning("í™”ë©´ ì´íƒˆ", "ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•ŠìŒ", duration)
        
        # 3. ê³ ê°œ ë°©í–¥ ê°ì§€
        current_head_abnormal = head_direction in ["Left", "Right", "Down"]
        if current_head_abnormal != self.is_head_abnormal:
            if not current_head_abnormal and self.is_head_violation:
                total_duration = current_time - self.head_abnormal_start_time
                self.print_violation_alert("ê³ ê°œ ë°©í–¥", f"ë°©í–¥: {head_direction}", 
                                         is_start=False, duration=total_duration)
            
            self.is_head_abnormal = current_head_abnormal
            self.head_abnormal_start_time = current_time
            self.is_head_violation = False
        
        if self.is_head_abnormal:
            duration = current_time - self.head_abnormal_start_time
            if duration >= self.SUSTAINED_TIME and not self.is_head_violation:
                self.is_head_violation = True
                self.print_violation_alert("ê³ ê°œ ë°©í–¥", f"ë°©í–¥: {head_direction}", 
                                         is_start=True, duration=duration)
            elif duration < self.SUSTAINED_TIME and duration > 0.5:
                self.print_warning("ê³ ê°œ ë°©í–¥", f"{head_direction} ë°©í–¥ìœ¼ë¡œ ì›€ì§ì„", duration)
        
        # 4. ì‹œì„  ì´íƒˆ ê°ì§€
        if self.gaze_baseline is not None and gaze_ratio != 1:
            current_gaze_abnormal = (gaze_ratio < self.gaze_baseline - self.GAZE_MARGIN or 
                                   gaze_ratio > self.gaze_baseline + self.GAZE_MARGIN)
            
            if current_gaze_abnormal != self.is_gaze_abnormal:
                if not current_gaze_abnormal and self.is_gaze_violation:
                    total_duration = current_time - self.gaze_abnormal_start_time
                    self.print_violation_alert("ì‹œì„  ì´íƒˆ", f"ì‹œì„  ë¹„ìœ¨: {gaze_ratio:.2f}", 
                                             is_start=False, duration=total_duration)
                
                self.is_gaze_abnormal = current_gaze_abnormal
                self.gaze_abnormal_start_time = current_time
                self.is_gaze_violation = False
            
            if self.is_gaze_abnormal:
                duration = current_time - self.gaze_abnormal_start_time
                if duration >= self.SUSTAINED_TIME and not self.is_gaze_violation:
                    self.is_gaze_violation = True
                    direction = "ì˜¤ë¥¸ìª½" if gaze_ratio < self.gaze_baseline else "ì™¼ìª½"
                    self.print_violation_alert("ì‹œì„  ì´íƒˆ", f"{direction} ë°©í–¥ìœ¼ë¡œ ì‹œì„  ì´íƒˆ", 
                                             is_start=True, duration=duration)
                elif duration < self.SUSTAINED_TIME and duration > 0.5:
                    direction = "ì˜¤ë¥¸ìª½" if gaze_ratio < self.gaze_baseline else "ì™¼ìª½"
                    deviation = abs(gaze_ratio - self.gaze_baseline)
                    self.print_warning("ì‹œì„  ì´íƒˆ", f"{direction} ì‹œì„  (í¸ì°¨: {deviation:.2f})", duration)
    
    def print_terminal_status(self, face_count, head_direction, gaze_ratio):
        """í„°ë¯¸ë„ì— ì‹¤ì‹œê°„ ìƒíƒœ ì¶œë ¥"""
        current_time = time.time()
        
        if current_time - self.last_status_print >= self.PRINT_INTERVAL:
            timestamp = datetime.now().strftime("%H:%M:%S")
            exam_duration = int(current_time - self.exam_start_time) if self.exam_start_time else 0
            
            status_msg = f"[{timestamp}] [{exam_duration:04d}s] "
            
            # ì–¼êµ´ ê°ì§€ ìƒíƒœ
            if face_count == 0:
                status_msg += f"{self.RED}ì–¼êµ´ ì—†ìŒ{self.END}"
            elif face_count == 1:
                status_msg += f"{self.GREEN}ì •ìƒ (1ëª…){self.END}"
            else:
                status_msg += f"{self.YELLOW}ë‹¤ì¤‘ ì¸ë¬¼ ({face_count}ëª…){self.END}"
            
            # ê³ ê°œ ë°©í–¥ ìƒíƒœ
            if head_direction == "Forward":
                status_msg += f" | ê³ ê°œ: {self.GREEN}ì •ë©´{self.END}"
            else:
                status_msg += f" | ê³ ê°œ: {self.YELLOW}{head_direction}{self.END}"
            
            # ì‹œì„  ìƒíƒœ
            if self.gaze_baseline is None:
                status_msg += f" | ì‹œì„ : {self.BLUE}ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì¤‘{self.END}"
            elif gaze_ratio != 1:
                if (gaze_ratio >= self.gaze_baseline - self.GAZE_MARGIN and 
                    gaze_ratio <= self.gaze_baseline + self.GAZE_MARGIN):
                    status_msg += f" | ì‹œì„ : {self.GREEN}ì •ìƒ{self.END}"
                else:
                    direction = "ì˜¤ë¥¸ìª½" if gaze_ratio < self.gaze_baseline else "ì™¼ìª½"
                    status_msg += f" | ì‹œì„ : {self.YELLOW}{direction} ì´íƒˆ{self.END}"
            
            print(status_msg)
            self.last_status_print = current_time
    
    def print_violation_alert(self, violation_type, details, is_start=True, duration=0):
        """ìœ„ë°˜ ì‚¬í•­ í„°ë¯¸ë„ ì•Œë¦¼"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        
        if is_start:
            print(f"\n{self.BOLD}{self.RED}ğŸš¨ ìœ„ë°˜ ê°ì§€! ğŸš¨{self.END}")
            print(f"{self.RED}â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”{self.END}")
            print(f"{self.RED}â”‚ ì‹œê°„: {timestamp:<20} ìœ í˜•: {violation_type:<20} â”‚{self.END}")
            print(f"{self.RED}â”‚ ìƒì„¸: {details:<50} â”‚{self.END}")
            print(f"{self.RED}â”‚ ì§€ì†ì‹œê°„: {duration:.1f}ì´ˆ{' ' * 40}â”‚{self.END}")
            print(f"{self.RED}â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜{self.END}")
            print()
            
            self.total_violations += 1
            self.log_violation(violation_type, details)
            
        else:
            print(f"{self.GREEN}[{timestamp}] ìœ„ë°˜ ì¢…ë£Œ: {violation_type} (ì´ ì§€ì†ì‹œê°„: {duration:.1f}ì´ˆ){self.END}")
    
    def print_warning(self, warning_type, details, duration):
        """ê²½ê³  ì‚¬í•­ í„°ë¯¸ë„ ì¶œë ¥"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        
        progress = min(duration / self.SUSTAINED_TIME, 1.0) * 100
        bar_length = 20
        filled_length = int(bar_length * progress / 100)
        bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)
        
        print(f"{self.YELLOW}[{timestamp}] âš ï¸  {warning_type}: {details} [{bar}] {progress:.0f}% ({duration:.1f}s){self.END}")
    
    def log_violation(self, violation_type, details):
        """ìœ„ë°˜ ì‚¬í•­ ë¡œê·¸ ê¸°ë¡"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = {
            "timestamp": timestamp,
            "user": self.authenticated_user,
            "type": violation_type,
            "details": details,
            "exam_duration": int(time.time() - self.exam_start_time) if self.exam_start_time else 0
        }
        self.violation_log.append(log_entry)
    
    def draw_status_info(self, frame, face_count, head_direction, gaze_ratio, x_ratio, y_ratio):
        """ìƒíƒœ ì •ë³´ë¥¼ í™”ë©´ì— í‘œì‹œ"""
        current_time = time.time()
        exam_duration = int(current_time - self.exam_start_time) if self.exam_start_time else 0
        
        # ê¸°ë³¸ ì •ë³´ í‘œì‹œ
        cv2.putText(frame, f"User: {self.authenticated_user}", (30, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        cv2.putText(frame, f"Exam Time: {exam_duration}s", (30, 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        cv2.putText(frame, f"Faces: {face_count}", (30, 90),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        cv2.putText(frame, f"Head: {head_direction}", (30, 120),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        if self.gaze_baseline is not None:
            cv2.putText(frame, f"Gaze: {gaze_ratio:.2f} (Base: {self.gaze_baseline:.2f})", (30, 150),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        else:
            cv2.putText(frame, f"Gaze: {gaze_ratio:.2f} (Calibrating...)", (30, 150),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        # ìœ„ë°˜ ìƒíƒœ í‘œì‹œ
        y_offset = 180
        
        violations = []
        if self.is_multiple_faces_violation:
            violations.append("Multiple Faces")
        if self.is_no_face_violation:
            violations.append("No Face")
        if self.is_head_violation:
            violations.append(f"Head: {head_direction}")
        if self.is_gaze_violation:
            violations.append("Gaze Direction")
        
        if violations:
            cv2.putText(frame, f"VIOLATIONS: {', '.join(violations)}", (30, y_offset),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
        
        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìƒíƒœ í‘œì‹œ
        if self.gaze_baseline is None:
            progress = (self.frame_count / self.BASELINE_FRAMES) * 100
            cv2.putText(frame, f"Eye Calibration: {self.frame_count}/{self.BASELINE_FRAMES} ({progress:.0f}%)", 
                       (30, frame.shape[0] - 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
            cv2.putText(frame, "Look forward and stay still", 
                       (30, frame.shape[0] - 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        # ìœ„ë°˜ íšŸìˆ˜ í‘œì‹œ
        cv2.putText(frame, f"Total Violations: {self.total_violations}", 
                   (frame.shape[1] - 300, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255) if self.total_violations > 0 else (0, 255, 0), 2)
    
    def exam_monitoring_phase(self, cap, out=None):
        """ì‹œí—˜ ê°ë… ë‹¨ê³„"""
        print(f"\n{self.BOLD}{self.GREEN}ğŸ“ 2ë‹¨ê³„: ì‹œí—˜ ê°ë… ì‹œì‘{self.END}")
        print(f"{self.GREEN}ì‘ì‹œì: {self.authenticated_user}{self.END}")
        print(f"{self.CYAN}ì‹¤ì‹œê°„ ë¶€ì •í–‰ìœ„ íƒì§€ ì‹œì‘...{self.END}")
        print(f"{self.YELLOW}í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤: ESC(ì¢…ë£Œ), M(ë¯¸ëŸ¬ë§), D(ë””ë²„ê·¸){self.END}")
        print("=" * 70)
        
        self.exam_start_time = time.time()
        
        while True:
            ret, frame = cap.read()
            if not ret:
                print(f"{self.RED}âŒ í”„ë ˆì„ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.{self.END}")
                break
            
            if self.MIRROR_CAMERA:
                frame = cv2.flip(frame, 1)
            
            if out:
                out.write(frame)
            
            # MediaPipe ì²˜ë¦¬
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            img_h, img_w = frame.shape[:2]
            
            results = self.face_mesh.process(frame_rgb)
            
            # ì´ˆê¸°ê°’ ì„¤ì •
            face_count = 0
            head_direction = "No Face"
            x_ratio, y_ratio = 0, 0
            gaze_ratio = 1
            
            if results.multi_face_landmarks:
                face_count = len(results.multi_face_landmarks)
                
                # ì²« ë²ˆì§¸ ì–¼êµ´ë¡œ ë¶„ì„
                best_face = results.multi_face_landmarks[0]
                current_landmarks = self.get_landmarks_coords(best_face, img_w, img_h)
                
                # ë¨¸ë¦¬ ë°©í–¥ ë¶„ì„
                head_direction, x_ratio, y_ratio = self.get_head_direction(current_landmarks, img_w, img_h)
                
                # ì‹œì„  ë¶„ì„
                landmarks_normalized = [(lm.x, lm.y) for lm in best_face.landmark]
                gaze_left = self.get_gaze_ratio(self.LEFT_EYE, landmarks_normalized, frame, gray)
                gaze_right = self.get_gaze_ratio(self.RIGHT_EYE, landmarks_normalized, frame, gray)
                current_gaze = (gaze_left + gaze_right) / 2
                
                # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì²˜ë¦¬
                if self.frame_count < self.BASELINE_FRAMES:
                    self.baseline_sum += current_gaze
                    self.frame_count += 1
                    
                    if self.frame_count == self.BASELINE_FRAMES:
                        self.gaze_baseline = self.baseline_sum / self.BASELINE_FRAMES
                        print(f"{self.BOLD}{self.GREEN}âœ… ì‹œì„  ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì™„ë£Œ! (ê¸°ì¤€ê°’: {self.gaze_baseline:.2f}){self.END}")
                    
                    gaze_ratio = current_gaze
                else:
                    gaze_ratio = current_gaze
                
                # ì–¼êµ´ ëœë“œë§ˆí¬ ì‹œê°í™” (ë¼ì¦ˆë² ë¦¬íŒŒì´ ìµœì í™” - ê°„ì†Œí™”)
                if self.GAZE_DEBUG_MODE:
                    self.mp_drawing.draw_landmarks(
                        frame, best_face, self.mp_face_mesh.FACEMESH_CONTOURS,
                        landmark_drawing_spec=None,
                        connection_drawing_spec=self.mp_drawing.DrawingSpec(
                            color=(0, 255, 255), thickness=1, circle_radius=1)
                    )
            
            # í„°ë¯¸ë„ ìƒíƒœ ì¶œë ¥
            self.print_terminal_status(face_count, head_direction, gaze_ratio)
            
            # ìœ„ë°˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            self.update_violation_states(face_count, head_direction, gaze_ratio)
            
            # í™”ë©´ì— ì •ë³´ í‘œì‹œ
            self.draw_status_info(frame, face_count, head_direction, gaze_ratio, x_ratio, y_ratio)
            
            # í”„ë ˆì„ í‘œì‹œ
            cv2.imshow("AI Exam Supervisor - Monitoring", frame)
            
            # í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬
            key = cv2.waitKey(1) & 0xFF
            if key == 27:  # ESC
                break
            elif key == ord('m') or key == ord('M'):
                self.MIRROR_CAMERA = not self.MIRROR_CAMERA
                print(f"{self.CYAN}ì¹´ë©”ë¼ ë¯¸ëŸ¬ë§: {'ON' if self.MIRROR_CAMERA else 'OFF'}{self.END}")
            elif key == ord('d') or key == ord('D'):
                self.GAZE_DEBUG_MODE = not self.GAZE_DEBUG_MODE
                print(f"{self.CYAN}ë””ë²„ê·¸ ëª¨ë“œ: {'ON' if self.GAZE_DEBUG_MODE else 'OFF'}{self.END}")
        
        return True
    
    def save_exam_report(self):
        """ì‹œí—˜ ê²°ê³¼ ë³´ê³ ì„œ ì €ì¥"""
        if not self.exam_start_time:
            return
        
        exam_duration = int(time.time() - self.exam_start_time)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        report = {
            "exam_info": {
                "user": self.authenticated_user,
                "start_time": datetime.fromtimestamp(self.exam_start_time).strftime("%Y-%m-%d %H:%M:%S"),
                "end_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "duration_seconds": exam_duration,
                "total_violations": self.total_violations
            },
            "violations": self.violation_log,
            "system_config": self.config
        }
        
        report_path = os.path.join(self.LOG_PATH, f"exam_report_{self.authenticated_user}_{timestamp}.json")
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            print(f"{self.GREEN}ğŸ“„ ì‹œí—˜ ë³´ê³ ì„œ ì €ì¥: {report_path}{self.END}")
        except Exception as e:
            print(f"{self.RED}âŒ ë³´ê³ ì„œ ì €ì¥ ì‹¤íŒ¨: {e}{self.END}")
    
    def print_final_report(self):
        """ìµœì¢… ê²°ê³¼ ì¶œë ¥"""
        if not self.exam_start_time:
            return
        
        exam_duration = int(time.time() - self.exam_start_time)
        
        print(f"\n{self.BOLD}{self.BLUE}=" * 70 + "{self.END}")
        print(f"{self.BOLD}{self.BLUE}ğŸ ì‹œí—˜ ì¢…ë£Œ - ìµœì¢… ê²°ê³¼{self.END}")
        print(f"{self.BOLD}{self.BLUE}=" * 70 + "{self.END}")
        
        print(f"{self.CYAN}ì‘ì‹œì: {self.authenticated_user}{self.END}")
        print(f"{self.CYAN}ì‹œí—˜ ì‹œê°„: {exam_duration // 60}ë¶„ {exam_duration % 60}ì´ˆ{self.END}")
        
        if self.total_violations > 0:
            print(f"{self.RED}ì´ ìœ„ë°˜ íšŸìˆ˜: {self.total_violations}íšŒ{self.END}")
            print(f"{self.RED}âš ï¸  ë¶€ì •í–‰ìœ„ ì˜ì‹¬ ì‚¬ë¡€ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤!{self.END}")
            
            # ìœ„ë°˜ ìœ í˜•ë³„ í†µê³„
            violation_types = {}
            for log in self.violation_log:
                vtype = log['type']
                violation_types[vtype] = violation_types.get(vtype, 0) + 1
            
            print(f"\n{self.BOLD}ğŸ“Š ìœ„ë°˜ ìœ í˜•ë³„ í†µê³„:{self.END}")
            for vtype, count in violation_types.items():
                print(f"  â€¢ {vtype}: {count}íšŒ")
                
        else:
            print(f"{self.GREEN}âœ… ìœ„ë°˜ ì‚¬í•­ ì—†ìŒ - ì •ìƒì ìœ¼ë¡œ ì‹œí—˜ì´ ì§„í–‰ë˜ì—ˆìŠµë‹ˆë‹¤{self.END}")
        
        print(f"{self.BOLD}{self.BLUE}=" * 70 + "{self.END}")
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        # ì¹´ë©”ë¼ ì´ˆê¸°í™”
        cap = self.find_camera()
        if cap is None:
            print(f"{self.RED}âŒ ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨{self.END}")
            return False
        
        # ë¹„ë””ì˜¤ ì €ì¥ ì„¤ì •
        out = None
        if self.SAVE_VIDEO:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            video_path = os.path.join(self.LOG_PATH, f"exam_video_{timestamp}.mp4")
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(video_path, fourcc, self.CAMERA_FPS, 
                                (self.CAMERA_WIDTH, self.CAMERA_HEIGHT))
        
        try:
            # 1ë‹¨ê³„: ì‹ ì› í™•ì¸
            if not self.identity_verification_phase(cap):
                return False
            
            # ë‹¨ê³„ ì „í™˜
            self.system_phase = "EXAM_MONITORING"
            cv2.destroyAllWindows()  # ì´ì „ ì°½ ë‹«ê¸°
            time.sleep(1)
            
            # 2ë‹¨ê³„: ì‹œí—˜ ê°ë…
            self.exam_monitoring_phase(cap, out)
            
            return True
            
        except KeyboardInterrupt:
            print(f"\n{self.YELLOW}ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.{self.END}")
            return False
        except Exception as e:
            print(f"{self.RED}âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}{self.END}")
            return False
        finally:
            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            cap.release()
            if out:
                out.release()
            cv2.destroyAllWindows()
            
            # ìµœì¢… ë³´ê³ ì„œ
            if self.authenticated_user:
                self.print_final_report()
                self.save_exam_report()
            
            print(f"{self.CYAN}ğŸ”’ AI ì‹œí—˜ ê°ë…ê´€ ì‹œìŠ¤í…œ ì¢…ë£Œ{self.END}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="AI ì‹œí—˜ ê°ë…ê´€ ì‹œìŠ¤í…œ v2.0")
    parser.add_argument("--config", default="config.json", help="ì„¤ì • íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--dataset", default="./dataset", help="ì–¼êµ´ ë°ì´í„°ì…‹ ê²½ë¡œ")
    parser.add_argument("--camera", type=int, default=0, help="ì¹´ë©”ë¼ ì¸ë±ìŠ¤")
    
    args = parser.parse_args()
    
    print(f"""
{chr(27)}[96mâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                   ğŸ¤– AI ì‹œí—˜ ê°ë…ê´€ ì‹œìŠ¤í…œ v2.0                      â•‘
â•‘                    (ë¼ì¦ˆë² ë¦¬íŒŒì´5 ìµœì í™” ë²„ì „)                        â•‘
â•‘                                                                       â•‘
â•‘  ğŸ‘¤ 1ë‹¨ê³„: ì‹ ì› í™•ì¸ (ì–¼êµ´ ì¸ì‹)                                      â•‘
â•‘  ğŸ” 2ë‹¨ê³„: ì‹¤ì‹œê°„ ë¶€ì •í–‰ìœ„ íƒì§€                                       â•‘
â•‘     â€¢ ë‹¤ì¤‘ ì¸ë¬¼ ê°ì§€                                                  â•‘
â•‘     â€¢ í™”ë©´ ì´íƒˆ ê°ì§€                                                  â•‘
â•‘     â€¢ ê³ ê°œ ë°©í–¥ ì¶”ì                                                   â•‘
â•‘     â€¢ ì‹œì„  ë°©í–¥ ì¶”ì                                                   â•‘
â•‘                                                                       â•‘
â•‘  ğŸ“ ë¡œê·¸ ë° ë³´ê³ ì„œ ìë™ ìƒì„±                                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{chr(27)}[0m
""")
    
    try:
        supervisor = AIExamSupervisorIntegrated(args.config)
        supervisor.run()
    except Exception as e:
        print(f"{chr(27)}[91mâŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}{chr(27)}[0m")
        sys.exit(1)

if __name__ == "__main__":
    main()
```
