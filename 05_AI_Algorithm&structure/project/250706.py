import cv2
import mediapipe as mp
import numpy as np
import face_recognition
import time
import os

# ëˆˆ EAR ê³„ì‚° í•¨ìˆ˜
def calculate_ear(landmarks, eye_indices):
    left = np.array([landmarks[eye_indices[0]].x, landmarks[eye_indices[0]].y])
    right = np.array([landmarks[eye_indices[3]].x, landmarks[eye_indices[3]].y])
    top = (np.array([landmarks[eye_indices[1]].x, landmarks[eye_indices[1]].y]) +
           np.array([landmarks[eye_indices[2]].x, landmarks[eye_indices[2]].y])) / 2
    bottom = (np.array([landmarks[eye_indices[4]].x, landmarks[eye_indices[4]].y]) +
              np.array([landmarks[eye_indices[5]].x, landmarks[eye_indices[5]].y])) / 2
    horizontal = np.linalg.norm(left - right)
    vertical = np.linalg.norm(top - bottom)
    return vertical / horizontal

# ëˆˆ ëœë“œë§ˆí¬ ì¸ë±ìŠ¤ (Mediapipe ê¸°ì¤€)
LEFT_EYE = [362, 385, 387, 263, 373, 380]
RIGHT_EYE = [33, 160, 158, 133, 153, 144]

mp_face_mesh = mp.solutions.face_mesh

# ì–¼êµ´ ì¸ì‹ ë° ë¹„êµ í•¨ìˆ˜
def authenticate_face(img_path, dataset_path="./dataset"):
    known_encodings = []
    known_names = []

    for filename in os.listdir(dataset_path):
        if filename.endswith(('.jpg', '.png')):
            image = face_recognition.load_image_file(os.path.join(dataset_path, filename))
            encodings = face_recognition.face_encodings(image)
            if encodings:
                known_encodings.append(encodings[0])
                known_names.append(os.path.splitext(filename)[0])

    unknown_image = face_recognition.load_image_file(img_path)
    unknown_encodings = face_recognition.face_encodings(unknown_image)

    if unknown_encodings:
        results = face_recognition.compare_faces(known_encodings, unknown_encodings[0], tolerance=0.4)
        distances = face_recognition.face_distance(known_encodings, unknown_encodings[0])

        if True in results:
            idx = results.index(True)
            print(f"âœ… ì‹ ì› í™•ì¸ ì„±ê³µ: {known_names[idx]} (ê±°ë¦¬: {distances[idx]:.4f})")
        else:
            print("âŒ ì‹ ì› í™•ì¸ ì‹¤íŒ¨: ë“±ë¡ëœ ì¸ë¬¼ì´ ì•„ë‹™ë‹ˆë‹¤.")
    else:
        print("â— ì–¼êµ´ ì¸ì‹ ì‹¤íŒ¨: ì´ë¯¸ì§€ì— ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ëˆˆ ê¹œë¹¡ì„ ê°ì§€ ë° ì‹ ì› í™•ì¸
def detect_blink_and_authenticate(dataset_path="./dataset"):
    cap = cv2.VideoCapture(2)  # ì¹´ë©”ë¼ ì¸ë±ìŠ¤ ì¡°ì • í•„ìš” ì‹œ ë³€ê²½
    blink_count = 0
    blink_flag = False
    start_time = time.time()
    DURATION = 6  # ì´ˆ
    BLINK_THRESHOLD = 0.21
    BLINK_REQUIRED = 2

    with mp_face_mesh.FaceMesh(
        max_num_faces=1,
        refine_landmarks=True,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5) as face_mesh:

        prev_ear = 0
        frame_to_save = None

        print("ğŸ“¸ ëˆˆ ê¹œë¹¡ì„ ê°ì§€ ì‹œì‘ (q í‚¤ë¡œ ì¢…ë£Œ)")

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = face_mesh.process(rgb)

            if results.multi_face_landmarks:
                for face_landmarks in results.multi_face_landmarks:
                    landmarks = face_landmarks.landmark
                    left_ear = calculate_ear(landmarks, LEFT_EYE)
                    right_ear = calculate_ear(landmarks, RIGHT_EYE)
                    ear = (left_ear + right_ear) / 2.0

                    # ë””ë²„ê¹… EAR ì¶œë ¥
                    cv2.putText(frame, f"EAR: {ear:.3f}", (30, 30),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

                    if ear < BLINK_THRESHOLD and not blink_flag:
                        blink_count += 1
                        blink_flag = True
                        print(f"ğŸ‘ ëˆˆ ê¹œë¹¡ì„ ê°ì§€! ì´ {blink_count}íšŒ")

                    if ear >= BLINK_THRESHOLD:
                        blink_flag = False

                    frame_to_save = frame.copy()

            cv2.imshow('Blink Detection', frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

            if time.time() - start_time > DURATION:
                break

        cap.release()
        cv2.destroyAllWindows()

        if blink_count >= BLINK_REQUIRED and frame_to_save is not None:
            print("âœ… ì‹¤ì œ ì‚¬ëŒìœ¼ë¡œ íŒë³„ë¨. ì‹ ì› í™•ì¸ ì‹œì‘...")
            img_path = "capture.jpg"
            cv2.imwrite(img_path, frame_to_save)
            authenticate_face(img_path, dataset_path)
        else:
            print("âŒ ì‚¬ì§„ìœ¼ë¡œ íŒë³„ë¨ (ëˆˆ ê¹œë¹¡ì„ ê°ì§€ë˜ì§€ ì•ŠìŒ).")

# ì‹¤í–‰
if __name__ == "__main__":
    detect_blink_and_authenticate(dataset_path="./dataset")
