```python
import cv2
import face_recognition
import os
import dlib
from scipy.spatial import distance
from datetime import datetime

# ------------------- ëˆˆ ê¹œë°•ì„ ë¼ì´ë¸Œë‹ˆìŠ¤ ì²´í¬ í•¨ìˆ˜ -------------------
def eye_aspect_ratio(eye):
    A = distance.euclidean(eye[1], eye[5])
    B = distance.euclidean(eye[2], eye[4])
    C = distance.euclidean(eye[0], eye[3])
    ear = (A + B) / (2.0 * C)
    return ear

EYE_AR_THRESH = 0.25
EYE_AR_CONSEC_FRAMES = 3

detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")  # í•„ìš”: dlib ëª¨ë¸ íŒŒì¼

(lStart, lEnd) = (42, 48)  # ì˜¤ë¥¸ìª½ ëˆˆ
(rStart, rEnd) = (36, 42)  # ì™¼ìª½ ëˆˆ

blink_counter = 0
total_blinks = 0
liveness_confirmed = False

# ------------------- ì–¼êµ´ ë¹„êµ í•¨ìˆ˜ -------------------
match_found = False

def compare_with_dataset(captured_image_path, dataset_path="./dataset"):
    global match_found
    unknown_image = face_recognition.load_image_file(captured_image_path)
    face_locations = face_recognition.face_locations(unknown_image, model="cnn")
    unknown_encodings = face_recognition.face_encodings(unknown_image, face_locations)

    if len(unknown_encodings) == 0:
        print("â— ìº¡ì²˜ëœ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return False

    unknown_encoding = unknown_encodings[0]

    for filename in os.listdir(dataset_path):
        if filename.lower().endswith((".jpg", ".jpeg", ".png")):
            path = os.path.join(dataset_path, filename)
            known_image = face_recognition.load_image_file(path)
            known_encodings = face_recognition.face_encodings(known_image)

            if not known_encodings:
                print(f"â— ë°ì´í„°ì…‹ ì–¼êµ´ ì¸ì‹ ì‹¤íŒ¨: {filename}")
                continue

            known_encoding = known_encodings[0]
            result = face_recognition.compare_faces([known_encoding], unknown_encoding, tolerance=0.4)
            distance_val = face_recognition.face_distance([known_encoding], unknown_encoding)[0]

            if (result[0]) & (match_found == False):
                print(f"âœ… [ì¼ì¹˜] ìº¡ì²˜: {captured_image_path} â†” ë°ì´í„°ì…‹: {filename} (ê±°ë¦¬: {distance_val:.4f})")
                match_found = True
                name = os.path.splitext(filename)[0]
                print(f"{name} ë‹˜ ì‹œí—˜ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.")
                return True
            else:
                print(f"âŒ [ë¶ˆì¼ì¹˜] {filename} (ê±°ë¦¬: {distance_val:.4f})")

    print("ğŸ‘¤ ì¼ì¹˜í•˜ëŠ” ì‚¬ëŒì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    print("ğŸ‘¤ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    return False

# ------------------- ë©”ì¸ ë£¨í”„ -------------------
cap = cv2.VideoCapture(2)

w, h = 640, 480
fps = 30
cap.set(cv2.CAP_PROP_FRAME_WIDTH, w)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, h)
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter('output.mp4', fourcc, fps, (w, h))

i = 1  # ìº¡ì²˜ ì´ë¯¸ì§€ ì¸ë±ìŠ¤

print("ğŸ¥ ì›¹ìº  ì‹œì‘! ëˆˆ ê¹œë°•ì„ í›„ 'c' í‚¤ ëˆŒëŸ¬ ìº¡ì²˜, 'q' í‚¤ë¡œ ì¢…ë£Œ")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("âŒ í”„ë ˆì„ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        break

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = detector(gray)

    liveness_confirmed = False  # ë§¤ í”„ë ˆì„ ì´ˆê¸°í™”

    for face in faces:
        shape = predictor(gray, face)
        shape = [(shape.part(i).x, shape.part(i).y) for i in range(68)]

        leftEye = shape[lStart:lEnd]
        rightEye = shape[rStart:rEnd]

        leftEAR = eye_aspect_ratio(leftEye)
        rightEAR = eye_aspect_ratio(rightEye)

        ear = (leftEAR + rightEAR) / 2.0

        if ear < EYE_AR_THRESH:
            blink_counter += 1
        else:
            if blink_counter >= EYE_AR_CONSEC_FRAMES:
                total_blinks += 1
                print(f"ğŸ‘ï¸ ëˆˆ ê¹œë°•ì„ ê°ì§€ë¨! ì´ ê¹œë°•ì„: {total_blinks}")
                liveness_confirmed = True  # ê¹œë°•ì„ í™•ì¸ë¨!
            blink_counter = 0

        for (x, y) in leftEye + rightEye:
            cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)

    cv2.putText(frame, f"Blinks: {total_blinks}", (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

    out.write(frame)
    cv2.imshow("Live Recognition with Liveness Check", frame)

    key = cv2.waitKey(1) & 0xFF
    if key == ord('q'):
        print("ğŸ›‘ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        break
    elif key == ord('c'):
        if liveness_confirmed:
            filename = f"whoareyou{i}.png"
            cv2.imwrite(filename, frame)
            print(f"\nğŸ“¸ {filename} ì €ì¥ ì™„ë£Œ. ì–¼êµ´ ë¹„êµ ì‹œì‘...")
            success = compare_with_dataset(filename)
            print("-" * 60)
            i += 1
            if success:
                print("âœ… ì¸ì¦ ì„±ê³µ!")
            else:
                print("âŒ ì¸ì¦ ì‹¤íŒ¨!")
        else:
            print("âš ï¸ ë¼ì´ë¸Œë‹ˆìŠ¤ ì²´í¬ ì‹¤íŒ¨: ëˆˆ ê¹œë°•ì„ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‹¤ì œ ì‚¬ìš©ìë§Œ ì¸ì¦ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

cap.release()
out.release()
cv2.destroyAllWindows()
```
