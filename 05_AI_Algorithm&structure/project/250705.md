```python
import cv2
import face_recognition
import os
import dlib
from scipy.spatial import distance
from datetime import datetime

# ------------------- 눈 깜박임 라이브니스 체크 함수 -------------------
def eye_aspect_ratio(eye):
    A = distance.euclidean(eye[1], eye[5])
    B = distance.euclidean(eye[2], eye[4])
    C = distance.euclidean(eye[0], eye[3])
    ear = (A + B) / (2.0 * C)
    return ear

EYE_AR_THRESH = 0.25
EYE_AR_CONSEC_FRAMES = 3

detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor("shape_predictor_68_face_landmarks.dat")  # 필요: dlib 모델 파일

(lStart, lEnd) = (42, 48)  # 오른쪽 눈
(rStart, rEnd) = (36, 42)  # 왼쪽 눈

blink_counter = 0
total_blinks = 0
liveness_confirmed = False

# ------------------- 얼굴 비교 함수 -------------------
match_found = False

def compare_with_dataset(captured_image_path, dataset_path="./dataset"):
    global match_found
    unknown_image = face_recognition.load_image_file(captured_image_path)
    face_locations = face_recognition.face_locations(unknown_image, model="cnn")
    unknown_encodings = face_recognition.face_encodings(unknown_image, face_locations)

    if len(unknown_encodings) == 0:
        print("❗ 캡처된 이미지에서 얼굴을 찾지 못했습니다.")
        return False

    unknown_encoding = unknown_encodings[0]

    for filename in os.listdir(dataset_path):
        if filename.lower().endswith((".jpg", ".jpeg", ".png")):
            path = os.path.join(dataset_path, filename)
            known_image = face_recognition.load_image_file(path)
            known_encodings = face_recognition.face_encodings(known_image)

            if not known_encodings:
                print(f"❗ 데이터셋 얼굴 인식 실패: {filename}")
                continue

            known_encoding = known_encodings[0]
            result = face_recognition.compare_faces([known_encoding], unknown_encoding, tolerance=0.4)
            distance_val = face_recognition.face_distance([known_encoding], unknown_encoding)[0]

            if (result[0]) & (match_found == False):
                print(f"✅ [일치] 캡처: {captured_image_path} ↔ 데이터셋: {filename} (거리: {distance_val:.4f})")
                match_found = True
                name = os.path.splitext(filename)[0]
                print(f"{name} 님 시험을 시작하겠습니다.")
                return True
            else:
                print(f"❌ [불일치] {filename} (거리: {distance_val:.4f})")

    print("👤 일치하는 사람을 찾지 못했습니다.")
    print("👤 다시 시도해주세요.")
    return False

# ------------------- 메인 루프 -------------------
cap = cv2.VideoCapture(2)

w, h = 640, 480
fps = 30
cap.set(cv2.CAP_PROP_FRAME_WIDTH, w)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, h)
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter('output.mp4', fourcc, fps, (w, h))

i = 1  # 캡처 이미지 인덱스

print("🎥 웹캠 시작! 눈 깜박임 후 'c' 키 눌러 캡처, 'q' 키로 종료")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("❌ 프레임을 가져올 수 없습니다.")
        break

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = detector(gray)

    liveness_confirmed = False  # 매 프레임 초기화

    for face in faces:
        shape = predictor(gray, face)
        shape = [(shape.part(i).x, shape.part(i).y) for i in range(68)]

        leftEye = shape[lStart:lEnd]
        rightEye = shape[rStart:rEnd]

        leftEAR = eye_aspect_ratio(leftEye)
        rightEAR = eye_aspect_ratio(rightEye)

        ear = (leftEAR + rightEAR) / 2.0

        if ear < EYE_AR_THRESH:
            blink_counter += 1
        else:
            if blink_counter >= EYE_AR_CONSEC_FRAMES:
                total_blinks += 1
                print(f"👁️ 눈 깜박임 감지됨! 총 깜박임: {total_blinks}")
                liveness_confirmed = True  # 깜박임 확인됨!
            blink_counter = 0

        for (x, y) in leftEye + rightEye:
            cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)

    cv2.putText(frame, f"Blinks: {total_blinks}", (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

    out.write(frame)
    cv2.imshow("Live Recognition with Liveness Check", frame)

    key = cv2.waitKey(1) & 0xFF
    if key == ord('q'):
        print("🛑 종료합니다.")
        break
    elif key == ord('c'):
        if liveness_confirmed:
            filename = f"whoareyou{i}.png"
            cv2.imwrite(filename, frame)
            print(f"\n📸 {filename} 저장 완료. 얼굴 비교 시작...")
            success = compare_with_dataset(filename)
            print("-" * 60)
            i += 1
            if success:
                print("✅ 인증 성공!")
            else:
                print("❌ 인증 실패!")
        else:
            print("⚠️ 라이브니스 체크 실패: 눈 깜박임이 감지되지 않았습니다. 실제 사용자만 인증 가능합니다.")

cap.release()
out.release()
cv2.destroyAllWindows()
```
