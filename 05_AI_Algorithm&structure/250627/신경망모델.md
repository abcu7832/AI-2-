# D05 신경망모델

## MNIST 실습
* MLP
```python

```
* MLP 기반의 FCNN
```python
# 기본 라이브러리 불러오기
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image

# -------------------------------
# 데이터셋 불러오기 (MNIST)
# -------------------------------
from tensorflow.keras.datasets import mnist
(train_x, train_y), (test_x, test_y) = mnist.load_data()

# 데이터 형태 확인
print("Train:", train_x.shape, train_y.shape)
print("Test:", test_x.shape, test_y.shape)

# 이미지 한 장 확인
img = train_x[0]
img1 = Image.fromarray(img, mode='L')
plt.imshow(img1, cmap='gray')
plt.title(f"Label: {train_y[0]}")
plt.axis('off')
plt.show()

# -------------------------------
# 데이터 전처리
# -------------------------------
train_x_flat = train_x.reshape(60000, -1) / 255.0
test_x_flat = test_x.reshape(10000, -1) / 255.0

# -------------------------------
# 모델 설정 (다층 퍼셉트론)
# -------------------------------
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

model = Sequential()
model.add(Dense(128, activation='relu', input_shape=(32*32,)))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))  # 0~9 숫자 분류

model.summary()

# -------------------------------
# 모델 컴파일 및 학습
# -------------------------------
model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer='sgd',
    metrics=['accuracy']
)

hist = model.fit(
    train_x_flat, train_y,
    epochs=30,
    batch_size=64,
    validation_split=0.2,
    verbose=1
)

# -------------------------------
# 학습 결과 시각화
# -------------------------------
acc = hist.history['accuracy']
val_acc = hist.history['val_accuracy']
loss = hist.history['loss']
val_loss = hist.history['val_loss']
epoch = np.arange(1, len(acc)+1)

# 정확도 그래프
plt.figure(figsize=(10, 6))
plt.plot(epoch, acc, 'b', label='Training Accuracy')
plt.plot(epoch, val_acc, 'r', label='Validation Accuracy')
plt.title('Training & Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

# 손실 그래프
plt.figure(figsize=(10, 6))
plt.plot(epoch, loss, label='Training Loss')
plt.plot(epoch, val_loss, label='Validation Loss')
plt.title('Training & Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

# 8. 최종 정확도 및 손실 출력
final_train_acc = hist.history['accuracy'][-1]
final_val_acc = hist.history['val_accuracy'][-1]
final_train_loss = hist.history['loss'][-1]
final_val_loss = hist.history['val_loss'][-1]

print(f"최종 학습 정확도: {final_train_acc:.4f}")
print(f"최종 검증 정확도: {final_val_acc:.4f}")
print(f"최종 학습 손실: {final_train_loss:.4f}")
print(f"최종 검증 손실: {final_val_loss:.4f}")

# 9. 테스트 데이터 평가 및 출력
test_loss, test_acc = model.evaluate(test_x_flat, test_y, verbose=0)
print(f"테스트 정확도: {test_acc:.4f}")
print(f"테스트 손실: {test_loss:.4f}")
```
![images_mnist_모델](/images/250628_MNIST.JPG)
![images_mnist_학습곡선](/images/250628_MNIST_l.JPG)
![images_mnist_loss](/images/250628_MNIST_loss.JPG)

## CIFAR10 실습
* MLP
```python
# 기본 라이브러리 불러오기
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

# -------------------------------
# CIFAR-10 데이터셋 불러오기
# -------------------------------
from tensorflow.keras.datasets import cifar10
(train_x, train_y), (test_x, test_y) = cifar10.load_data()

# 클래스 이름 정의
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

# -------------------------------
# 데이터 전처리
# -------------------------------
train_x_flat = train_x.reshape(50000, -1) / 255.0
test_x_flat = test_x.reshape(10000, -1) / 255.0

# -------------------------------
# 모델 설정 (다층 퍼셉트론)
# -------------------------------
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential([
    Dense(128, activation='relu', input_shape=(32*32*3,)),
    Dense(64, activation='relu'),
    Dense(32, activation='relu'),
    Dense(10, activation='softmax')
])

model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer='sgd',
    metrics=['accuracy']
)

# -------------------------------
# 모델 학습
# -------------------------------
hist = model.fit(
    train_x_flat, train_y,
    epochs=150,
    batch_size=16,
    validation_split=0.2,
    verbose=1
)

# -------------------------------
# 학습 결과 시각화
# -------------------------------
acc = hist.history['accuracy']
val_acc = hist.history['val_accuracy']
loss = hist.history['loss']
val_loss = hist.history['val_loss']
epochs = np.arange(1, len(acc)+1)

plt.figure(figsize=(10, 6))
plt.plot(epochs, acc, label='Train Accuracy')
plt.plot(epochs, val_acc, label='Validation Accuracy')
plt.title('Training & Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 6))
plt.plot(epochs, loss, label='Train Loss')
plt.plot(epochs, val_loss, label='Validation Loss')
plt.title('Training & Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

# -------------------------------
# 최종 정확도 및 손실 출력
# -------------------------------
print(f"최종 학습 정확도: {acc[-1]:.4f}")
print(f"최종 검증 정확도: {val_acc[-1]:.4f}")
print(f"최종 학습 손실: {loss[-1]:.4f}")
print(f"최종 검증 손실: {val_loss[-1]:.4f}")

# -------------------------------
# 테스트 평가
# -------------------------------
test_loss, test_acc = model.evaluate(test_x_flat, test_y, verbose=0)
print(f"테스트 정확도: {test_acc:.4f}")
print(f"테스트 손실: {test_loss:.4f}")

# -------------------------------
# 테스트 이미지 하나 예측 + 시각화
# -------------------------------
sample_idx = 0  # 첫 번째 테스트 이미지
sample_img = test_x[sample_idx]
sample_input = test_x_flat[sample_idx].reshape(1, -1)

pred = model.predict(sample_input)
pred_class = np.argmax(pred)

plt.figure(figsize=(3, 3))
plt.imshow(sample_img)
plt.title(f"예측: {class_names[pred_class]} (정답: {class_names[test_y[sample_idx][0]]})")
plt.axis('off')
plt.show()
```

* MLP 기반의 FCNN
```python
# 기본 라이브러리 불러오기
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

# -------------------------------
# CIFAR-10 데이터셋 불러오기
# -------------------------------
from tensorflow.keras.datasets import cifar10
(train_x, train_y), (test_x, test_y) = cifar10.load_data()

# 클래스 이름 정의
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

# -------------------------------
# 데이터 전처리
# -------------------------------
train_x_flat = train_x.reshape(50000, -1) / 255.0
test_x_flat = test_x.reshape(10000, -1) / 255.0

# -------------------------------
# 모델 설정 (다층 퍼셉트론)
# -------------------------------
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

model = Sequential([
    Dense(128, activation='relu', input_shape=(32*32*3,)),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(10, activation='softmax')
])

model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer='sgd',
    metrics=['accuracy']
)

# -------------------------------
# 모델 학습
# -------------------------------
hist = model.fit(
    train_x_flat, train_y,
    epochs=30,
    batch_size=64,
    validation_split=0.2,
    verbose=1
)

# -------------------------------
# 학습 결과 시각화
# -------------------------------
acc = hist.history['accuracy']
val_acc = hist.history['val_accuracy']
loss = hist.history['loss']
val_loss = hist.history['val_loss']
epochs = np.arange(1, len(acc)+1)

plt.figure(figsize=(10, 6))
plt.plot(epochs, acc, label='Train Accuracy')
plt.plot(epochs, val_acc, label='Validation Accuracy')
plt.title('Training & Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 6))
plt.plot(epochs, loss, label='Train Loss')
plt.plot(epochs, val_loss, label='Validation Loss')
plt.title('Training & Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

# -------------------------------
# 최종 정확도 및 손실 출력
# -------------------------------
print(f"최종 학습 정확도: {acc[-1]:.4f}")
print(f"최종 검증 정확도: {val_acc[-1]:.4f}")
print(f"최종 학습 손실: {loss[-1]:.4f}")
print(f"최종 검증 손실: {val_loss[-1]:.4f}")

# -------------------------------
# 테스트 평가
# -------------------------------
test_loss, test_acc = model.evaluate(test_x_flat, test_y, verbose=0)
print(f"테스트 정확도: {test_acc:.4f}")
print(f"테스트 손실: {test_loss:.4f}")

# -------------------------------
# 테스트 이미지 하나 예측 + 시각화
# -------------------------------
sample_idx = 0  # 첫 번째 테스트 이미지
sample_img = test_x[sample_idx]
sample_input = test_x_flat[sample_idx].reshape(1, -1)

pred = model.predict(sample_input)
pred_class = np.argmax(pred)

plt.figure(figsize=(3, 3))
plt.imshow(sample_img)
plt.title(f"예측: {class_names[pred_class]} (정답: {class_names[test_y[sample_idx][0]]})")
plt.axis('off')
plt.show()
```

## CIFAR10 실습
* MLP
```python
# 기본 라이브러리 불러오기
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

# -------------------------------
# CIFAR-10 데이터셋 불러오기
# -------------------------------
from tensorflow.keras.datasets import cifar10
(train_x, train_y), (test_x, test_y) = cifar10.load_data()

# 클래스 이름 정의
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

# -------------------------------
# 데이터 전처리
# -------------------------------
train_x_flat = train_x.reshape(50000, -1) / 255.0
test_x_flat = test_x.reshape(10000, -1) / 255.0

# -------------------------------
# 모델 설정 (다층 퍼셉트론)
# -------------------------------
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential([
    Dense(128, activation='relu', input_shape=(32*32*3,)),
    Dense(64, activation='relu'),
    Dense(32, activation='relu'),
    Dense(10, activation='softmax')
])

model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer='sgd',
    metrics=['accuracy']
)

# -------------------------------
# 모델 학습
# -------------------------------
hist = model.fit(
    train_x_flat, train_y,
    epochs=150,
    batch_size=16,
    validation_split=0.2,
    verbose=1
)

# -------------------------------
# 학습 결과 시각화
# -------------------------------
acc = hist.history['accuracy']
val_acc = hist.history['val_accuracy']
loss = hist.history['loss']
val_loss = hist.history['val_loss']
epochs = np.arange(1, len(acc)+1)

plt.figure(figsize=(10, 6))
plt.plot(epochs, acc, label='Train Accuracy')
plt.plot(epochs, val_acc, label='Validation Accuracy')
plt.title('Training & Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 6))
plt.plot(epochs, loss, label='Train Loss')
plt.plot(epochs, val_loss, label='Validation Loss')
plt.title('Training & Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

# -------------------------------
# 최종 정확도 및 손실 출력
# -------------------------------
print(f"최종 학습 정확도: {acc[-1]:.4f}")
print(f"최종 검증 정확도: {val_acc[-1]:.4f}")
print(f"최종 학습 손실: {loss[-1]:.4f}")
print(f"최종 검증 손실: {val_loss[-1]:.4f}")

# -------------------------------
# 테스트 평가
# -------------------------------
test_loss, test_acc = model.evaluate(test_x_flat, test_y, verbose=0)
print(f"테스트 정확도: {test_acc:.4f}")
print(f"테스트 손실: {test_loss:.4f}")

# -------------------------------
# 테스트 이미지 하나 예측 + 시각화
# -------------------------------
sample_idx = 0  # 첫 번째 테스트 이미지
sample_img = test_x[sample_idx]
sample_input = test_x_flat[sample_idx].reshape(1, -1)

pred = model.predict(sample_input)
pred_class = np.argmax(pred)

plt.figure(figsize=(3, 3))
plt.imshow(sample_img)
plt.title(f"예측: {class_names[pred_class]} (정답: {class_names[test_y[sample_idx][0]]})")
plt.axis('off')
plt.show()
```
![images_mnist_모델](/images/250628_MNIST.JPG)
![images_mnist_학습곡선](/images/250628_MNIST_l.JPG)
![images_mnist_loss](/images/250628_MNIST_loss.JPG)
* MLP 기반의 FCNN
```python
# 기본 라이브러리 불러오기
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

# -------------------------------
# CIFAR-10 데이터셋 불러오기
# -------------------------------
from tensorflow.keras.datasets import cifar10
(train_x, train_y), (test_x, test_y) = cifar10.load_data()

# 클래스 이름 정의
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

# -------------------------------
# 데이터 전처리
# -------------------------------
train_x_flat = train_x.reshape(50000, -1) / 255.0
test_x_flat = test_x.reshape(10000, -1) / 255.0

# -------------------------------
# 모델 설정 (다층 퍼셉트론)
# -------------------------------
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

model = Sequential([
    Dense(128, activation='relu', input_shape=(32*32*3,)),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(10, activation='softmax')
])

model.compile(
    loss='sparse_categorical_crossentropy',
    optimizer='sgd',
    metrics=['accuracy']
)

# -------------------------------
# 모델 학습
# -------------------------------
hist = model.fit(
    train_x_flat, train_y,
    epochs=30,
    batch_size=64,
    validation_split=0.2,
    verbose=1
)

# -------------------------------
# 학습 결과 시각화
# -------------------------------
acc = hist.history['accuracy']
val_acc = hist.history['val_accuracy']
loss = hist.history['loss']
val_loss = hist.history['val_loss']
epochs = np.arange(1, len(acc)+1)

plt.figure(figsize=(10, 6))
plt.plot(epochs, acc, label='Train Accuracy')
plt.plot(epochs, val_acc, label='Validation Accuracy')
plt.title('Training & Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 6))
plt.plot(epochs, loss, label='Train Loss')
plt.plot(epochs, val_loss, label='Validation Loss')
plt.title('Training & Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

# -------------------------------
# 최종 정확도 및 손실 출력
# -------------------------------
print(f"최종 학습 정확도: {acc[-1]:.4f}")
print(f"최종 검증 정확도: {val_acc[-1]:.4f}")
print(f"최종 학습 손실: {loss[-1]:.4f}")
print(f"최종 검증 손실: {val_loss[-1]:.4f}")

# -------------------------------
# 테스트 평가
# -------------------------------
test_loss, test_acc = model.evaluate(test_x_flat, test_y, verbose=0)
print(f"테스트 정확도: {test_acc:.4f}")
print(f"테스트 손실: {test_loss:.4f}")

# -------------------------------
# 테스트 이미지 하나 예측 + 시각화
# -------------------------------
sample_idx = 0  # 첫 번째 테스트 이미지
sample_img = test_x[sample_idx]
sample_input = test_x_flat[sample_idx].reshape(1, -1)

pred = model.predict(sample_input)
pred_class = np.argmax(pred)

plt.figure(figsize=(3, 3))
plt.imshow(sample_img)
plt.title(f"예측: {class_names[pred_class]} (정답: {class_names[test_y[sample_idx][0]]})")
plt.axis('off')
plt.show()
```
![images_mnist_모델](/images/250628_MNIST.JPG)
![images_mnist_학습곡선](/images/250628_MNIST_l.JPG)
![images_mnist_loss](/images/250628_MNIST_loss.JPG)
